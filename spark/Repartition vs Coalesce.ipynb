{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8c30b0-2771-42a8-8dbb-3f8ff6610213",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a21e570f-725d-4f71-8be8-037ca57f2005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "flight_df=spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"inferSchema\",\"true\")\\\n",
    "    .load(\"/Volumes/workspace/default/files/2010-summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b265f3b-6afa-416c-bf5d-7de12ae4057a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n+--------------------+-------------------+-----+\n|       United States|            Romania|    1|\n|       United States|            Ireland|  264|\n|       United States|              India|   69|\n|               Egypt|      United States|   24|\n|   Equatorial Guinea|      United States|    1|\n|       United States|          Singapore|   25|\n|       United States|            Grenada|   54|\n|          Costa Rica|      United States|  477|\n|             Senegal|      United States|   29|\n|       United States|   Marshall Islands|   44|\n|              Guyana|      United States|   17|\n|       United States|       Sint Maarten|   53|\n|               Malta|      United States|    1|\n|             Bolivia|      United States|   46|\n|            Anguilla|      United States|   21|\n|Turks and Caicos ...|      United States|  136|\n|       United States|        Afghanistan|    2|\n|Saint Vincent and...|      United States|    1|\n|               Italy|      United States|  390|\n|       United States|             Russia|  156|\n+--------------------+-------------------+-----+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "flight_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a036765a-84a6-4c65-8437-e81dc24a774d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22a8544e-fc32-4533-8140-f071e6b59ebc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "partition_flight_df=flight_df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f68931f6-8fcf-4f62-8d34-d23f46d6e023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n|partitionId|count|\n+-----------+-----+\n|          0|   63|\n|          1|   64|\n|          2|   64|\n|          3|   64|\n+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "partition_flight_df.withColumn(\"partitionId\",spark_partition_id()).groupBy(\"partitionId\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90d608ea-06c4-43ca-804f-211fe633db4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coalease_flight_df=flight_df.repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "467a6af6-aa9d-4d6e-a9c4-542e67fbb4f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n|partitionId|count|\n+-----------+-----+\n|          0|   32|\n|          1|   31|\n|          2|   32|\n|          3|   32|\n|          4|   32|\n|          5|   32|\n|          6|   32|\n|          7|   32|\n+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "coalease_flight_df.withColumn(\"partitionId\",spark_partition_id()).groupBy(\"partitionId\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c168f01-d6f1-4d80-98d7-ef1a0151c5a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "three_coalease_flight_df=coalease_flight_df.coalesce(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35802997-5de8-4a88-8c32-cecd0c1bcd84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n|partitionId|count|\n+-----------+-----+\n|          0|   63|\n|          1|   96|\n|          2|   96|\n+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "three_coalease_flight_df.withColumn(\"partitionId\",spark_partition_id()).groupBy(\"partitionId\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "513e7104-3934-4f5c-b568-a88ca64127e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "① **What is repartitioning in Spark?**\n",
    "\n",
    "- `repartition()` is used to increase or decrease the number of partitions in a DataFrame or RDD.\n",
    "- It always involves a **full shuffle** of the data across the cluster.\n",
    "- This ensures that data is **evenly distributed** across the specified partitions.\n",
    "\n",
    "**Example:**  \n",
    "python\n",
    "df.repartition(10)  # creates 10 partitions with roughly equal data\n",
    "\n",
    "\n",
    "👉 **Use case:**  \n",
    "Use `repartition()` when you need better parallelism, such as before wide transformations or writing to files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4464cba-549a-4ad7-b3ec-2d39f36512d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " ② What is coalesce in Spark?\n",
    " \n",
    " **coalesce()** is used to decrease the number of partitions in a DataFrame (cannot efficiently increase partitions).\n",
    " - It avoids a full shuffle by merging existing partitions.\n",
    " - Faster than repartition(), but may result in uneven data distribution.\n",
    " - Example: `df.coalesce(2)` reduces the DataFrame to 2 partitions by merging, with no shuffle.\n",
    " - **Use case:** When you want to reduce partitions, such as optimizing file writes with fewer output files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9481e8a0-2f9b-4d7e-aaee-f98b3b401012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "③ **Which one will you choose and why?**\n",
    "\n",
    "**Choose `repartition()` if:**\n",
    "- You want to **increase** the number of partitions.\n",
    "- You need a **balanced distribution** of data.\n",
    "- You're preparing data for **parallel processing**.\n",
    "\n",
    "**Choose `coalesce()` if:**\n",
    "- You only want to **reduce** the number of partitions.\n",
    "- **Performance** is more important than perfect balance.\n",
    "- You want to **avoid a full shuffle** and **save time**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09facae7-a876-4cd5-bd91-ce85cb7a22db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "🔥 Interview Tip:\n",
    "If asked in an interview:\n",
    "\n",
    "“If I want to reduce partitions before writing to HDFS, which is better?” → Coalesce.\n",
    "\n",
    "“If I want evenly distributed partitions for parallelism?” → Repartition."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Repartition vs Coalesce",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
